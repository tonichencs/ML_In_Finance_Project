{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gplearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsqycdKO2L7Z",
        "outputId": "cbdd918d-dc69-4e9a-fc5b-954e139f817b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gplearn\n",
            "  Downloading gplearn-0.4.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gplearn) (1.5.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.6.0)\n",
            "Downloading gplearn-0.4.2-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: gplearn\n",
            "Successfully installed gplearn-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBhTXzDZ1woP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from gplearn.genetic import SymbolicTransformer, SymbolicClassifier, SymbolicRegressor\n",
        "from gplearn.functions import make_function\n",
        "from gplearn.fitness import make_fitness\n",
        "from google.colab import drive\n",
        "\n",
        "import hashlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUg_U-8t9Hws",
        "outputId": "bfe484d2-c87c-475a-efd6-d2a1424ddcee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_data = pd.read_csv(\"/content/drive/MyDrive/final_data.csv\")\n",
        "stock_data  = stock_data [stock_data ['date'].between('2009-01-01', '2024-12-31')]"
      ],
      "metadata": {
        "id": "WQUcOD4M9PaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_col = [\"PERMNO\", 'CUSIP', 'Ticker', 'SICCD','NAICS']\n",
        "time_col = ['MthCalDt']\n",
        "factor_col = ['mom_12','mom_6', 'vol_12', 'vol_6', 'rev_1', 'rvol_1',\"rsi_6\", 'trend_strength']\n",
        "market_col = ['qmj_safety','seas_11_15na', 'ret_3_1', 'iskew_ff3_21d', 'rskew_21d', 'sti_gr1a',\n",
        "              'earnings_variability', 'nfna_gr1a', 'seas_16_20an', 'corr_1260d']\n",
        "fin_col = ['capxy', 'chechy', 'cshfdy', 'cshpry', 'dltry', 'dpcy', 'epspxy', 'oibdpy', 'txty']"
      ],
      "metadata": {
        "id": "TtsRMBkXCyai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_features = factor_col + market_col + fin_col"
      ],
      "metadata": {
        "id": "fLofDBzbPyTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "stock_data[all_features] = scaler.fit_transform(stock_data[all_features])"
      ],
      "metadata": {
        "id": "zXT_i94o_VYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
        "\n",
        "def tanh_func(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def safe_log(x):\n",
        "    return np.log(np.abs(x) + 1e-8)\n",
        "\n",
        "def safe_div(x1, x2):\n",
        "    return np.where(np.abs(x2) < 1e-8, 0, x1 / x2)\n",
        "\n",
        "def safe_sqrt(x):\n",
        "    return np.sqrt(np.abs(x))\n",
        "\n",
        "def safe_exp(x):\n",
        "    return np.exp(np.clip(x, -10, 10))\n",
        "\n",
        "sigmoid_func = make_function(function=sigmoid, name='sigmoid', arity=1)\n",
        "tanh_function = make_function(function=tanh_func, name='tanh', arity=1)\n",
        "safe_log_func = make_function(function=safe_log, name='safe_log', arity=1)\n",
        "safe_div_func = make_function(function=safe_div, name='safe_div', arity=2)\n",
        "safe_sqrt_func = make_function(function=safe_sqrt, name='safe_sqrt', arity=1)\n",
        "safe_exp_func = make_function(function=safe_exp, name='safe_exp', arity=1)\n",
        "\n",
        "classification_functions = ['add', 'sub', 'mul', safe_div_func, sigmoid_func, tanh_function, safe_sqrt_func, safe_exp_func]\n",
        "\n",
        "class ClassificationGeneticFactorGenerator:\n",
        "    def __init__(self, population_size=300, generations=10,\n",
        "                 tournament_size=20, stopping_criteria=0.01,\n",
        "                 const_range=(-2., 2.), init_depth=(2, 5),\n",
        "                 random_state=42, train_ratio=0.7):\n",
        "\n",
        "        self.population_size = population_size\n",
        "        self.generations = generations\n",
        "        self.tournament_size = tournament_size\n",
        "        self.stopping_criteria = stopping_criteria\n",
        "        self.const_range = const_range\n",
        "        self.init_depth = init_depth\n",
        "        self.random_state = random_state\n",
        "        self.train_ratio = train_ratio\n",
        "\n",
        "        self.generated_factors = {}\n",
        "        self.factor_expressions = {}\n",
        "        self.target_info = {}\n",
        "        self.trained_models = {}\n",
        "        self.label_encoder = None\n",
        "\n",
        "    def split_data(self, df):\n",
        "        n_train = int(len(df) * self.train_ratio)\n",
        "        train_df = df[df[\"year\"]<=2019].copy()\n",
        "        full_df = df.copy()\n",
        "        return train_df, full_df\n",
        "\n",
        "\n",
        "    def analyze_target(self, y):\n",
        "        unique_vals = np.unique(y)\n",
        "        n_unique = len(unique_vals)\n",
        "\n",
        "        target_info = {\n",
        "            'unique_values': unique_vals,\n",
        "            'n_unique': n_unique,\n",
        "            'is_binary': n_unique == 2,\n",
        "            'is_multiclass': n_unique > 2 and n_unique <= 10,\n",
        "            'distribution': pd.Series(y).value_counts().to_dict()\n",
        "        }\n",
        "\n",
        "        return target_info\n",
        "\n",
        "    def prepare_classification_target(self, y):\n",
        "        target_info = self.analyze_target(y)\n",
        "        self.target_info = target_info\n",
        "\n",
        "        if target_info['is_binary']:\n",
        "            if self.label_encoder is None:\n",
        "                self.label_encoder = LabelEncoder()\n",
        "                y_encoded = self.label_encoder.fit_transform(y).astype(float)\n",
        "            else:\n",
        "                y_encoded = self.label_encoder.transform(y).astype(float)\n",
        "            return y_encoded, 'binary'\n",
        "\n",
        "        elif target_info['is_multiclass']:\n",
        "            if self.label_encoder is None:\n",
        "                self.label_encoder = LabelEncoder()\n",
        "                y_encoded = self.label_encoder.fit_transform(y).astype(float)\n",
        "            else:\n",
        "                y_encoded = self.label_encoder.transform(y).astype(float)\n",
        "            return y_encoded, 'multiclass'\n",
        "\n",
        "        else:\n",
        "            return y.astype(float), 'regression'\n",
        "\n",
        "    def prepare_data(self, df, feature_cols, target_col):\n",
        "        X = df[feature_cols].copy()\n",
        "        X = X.fillna(X.median())\n",
        "        X = X.replace([np.inf, -np.inf], np.nan).fillna(X.median())\n",
        "\n",
        "        y = df[target_col].copy()\n",
        "        y = y.fillna(y.mode()[0] if not y.mode().empty else y.iloc[0])\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def apply_factor_to_data(self, X, model, factor_name, task_type):\n",
        "        try:\n",
        "            factor_values = model.predict(X)\n",
        "\n",
        "            if 'binary' in factor_name or task_type == 'binary':\n",
        "                factor_values = sigmoid(factor_values)\n",
        "            elif 'ordinal' in factor_name:\n",
        "                pass\n",
        "\n",
        "            return factor_values\n",
        "        except Exception as e:\n",
        "            print(f\"Error applying factor {factor_name}: {e}\")\n",
        "            return np.zeros(len(X))\n",
        "\n",
        "    def generate_binary_classification_factors(self, X_train, y_train, n_factors=5):\n",
        "        print(f\"Generating {n_factors} binary classification factors...\")\n",
        "\n",
        "        for i in range(n_factors):\n",
        "            try:\n",
        "                regressor = SymbolicRegressor(\n",
        "                    population_size=self.population_size,\n",
        "                    generations=self.generations,\n",
        "                    tournament_size=self.tournament_size,\n",
        "                    stopping_criteria=self.stopping_criteria,\n",
        "                    const_range=self.const_range,\n",
        "                    init_depth=self.init_depth,\n",
        "                    function_set=['add', 'sub', 'mul', safe_div_func, sigmoid_func],\n",
        "                    parsimony_coefficient=0.01,\n",
        "                    random_state=self.random_state + i,\n",
        "                    verbose=0,\n",
        "                    n_jobs=1\n",
        "                )\n",
        "\n",
        "                regressor.fit(X_train, y_train)\n",
        "\n",
        "                factor_name = f'genetic_binary_{i+1}'\n",
        "                self.trained_models[factor_name] = regressor\n",
        "                self.factor_expressions[factor_name] = str(regressor._program)\n",
        "\n",
        "                factor_values = regressor.predict(X_train)\n",
        "                factor_values = sigmoid(factor_values)\n",
        "\n",
        "                try:\n",
        "                    auc = roc_auc_score(y_train, factor_values)\n",
        "                    print(f\"  {factor_name} training AUC: {auc:.4f}\")\n",
        "                except:\n",
        "                    corr = np.corrcoef(factor_values, y_train)[0, 1]\n",
        "                    print(f\"  {factor_name} training correlation: {corr:.4f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Binary factor {i+1} training failed: {e}\")\n",
        "                continue\n",
        "\n",
        "    def generate_multiclass_factors(self, X_train, y_train, n_factors=5):\n",
        "        print(f\"Generating {n_factors} multiclass factors...\")\n",
        "\n",
        "        unique_classes = np.unique(y_train)\n",
        "        n_classes = len(unique_classes)\n",
        "        factors_per_class = max(1, n_factors // n_classes)\n",
        "\n",
        "        for class_idx, target_class in enumerate(unique_classes):\n",
        "            y_binary = (y_train == target_class).astype(float)\n",
        "\n",
        "            for i in range(factors_per_class):\n",
        "                try:\n",
        "                    regressor = SymbolicRegressor(\n",
        "                        population_size=max(200, self.population_size // 2),\n",
        "                        generations=max(10, self.generations // 2),\n",
        "                        tournament_size=self.tournament_size,\n",
        "                        stopping_criteria=self.stopping_criteria,\n",
        "                        const_range=self.const_range,\n",
        "                        init_depth=(1, 4),\n",
        "                        function_set=['add', 'sub', 'mul', safe_div_func, sigmoid_func],\n",
        "                        parsimony_coefficient=0.02,\n",
        "                        random_state=self.random_state + class_idx * 100 + i,\n",
        "                        verbose=0,\n",
        "                        n_jobs=1\n",
        "                    )\n",
        "\n",
        "                    regressor.fit(X_train, y_binary)\n",
        "\n",
        "                    factor_name = f'genetic_class_{target_class}_{i+1}'\n",
        "                    self.trained_models[factor_name] = regressor\n",
        "                    self.factor_expressions[factor_name] = str(regressor._program)\n",
        "\n",
        "                    factor_values = regressor.predict(X_train)\n",
        "                    factor_values = sigmoid(factor_values)\n",
        "\n",
        "                    try:\n",
        "                        auc = roc_auc_score(y_binary, factor_values)\n",
        "                        print(f\"  {factor_name} training AUC: {auc:.4f}\")\n",
        "                    except:\n",
        "                        corr = np.corrcoef(factor_values, y_binary)[0, 1]\n",
        "                        print(f\"  {factor_name} training correlation: {corr:.4f}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  Class {target_class} factor {i+1} training failed: {e}\")\n",
        "                    continue\n",
        "\n",
        "    def generate_ordinal_factors(self, X_train, y_train, n_factors=5):\n",
        "        print(f\"Generating {n_factors} ordinal factors...\")\n",
        "\n",
        "        for i in range(n_factors):\n",
        "            try:\n",
        "                regressor = SymbolicRegressor(\n",
        "                    population_size=self.population_size,\n",
        "                    generations=self.generations,\n",
        "                    tournament_size=self.tournament_size,\n",
        "                    stopping_criteria=self.stopping_criteria,\n",
        "                    const_range=self.const_range,\n",
        "                    init_depth=self.init_depth,\n",
        "                    function_set=['add', 'sub', 'mul', safe_div_func, tanh_function],\n",
        "                    parsimony_coefficient=0.01,\n",
        "                    random_state=self.random_state + i + 1000,\n",
        "                    verbose=0,\n",
        "                    n_jobs=1\n",
        "                )\n",
        "\n",
        "                regressor.fit(X_train, y_train)\n",
        "\n",
        "                factor_name = f'genetic_ordinal_{i+1}'\n",
        "                self.trained_models[factor_name] = regressor\n",
        "                self.factor_expressions[factor_name] = str(regressor._program)\n",
        "\n",
        "                factor_values = regressor.predict(X_train)\n",
        "\n",
        "                y_min, y_max = y_train.min(), y_train.max()\n",
        "                factor_min, factor_max = factor_values.min(), factor_values.max()\n",
        "                if factor_max > factor_min:\n",
        "                    factor_values = (factor_values - factor_min) / (factor_max - factor_min) * (y_max - y_min) + y_min\n",
        "\n",
        "                corr = np.corrcoef(factor_values, y_train)[0, 1]\n",
        "                print(f\"  {factor_name} training correlation: {corr:.4f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Ordinal factor {i+1} training failed: {e}\")\n",
        "                continue\n",
        "\n",
        "    def train_factors(self, train_df, feature_cols, target_col, n_factors=10):\n",
        "        print(\"=\" * 60)\n",
        "        print(\"Step 1: Training factors on training set\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        X_train, y_train = self.prepare_data(train_df, feature_cols, target_col)\n",
        "        y_processed, task_type = self.prepare_classification_target(y_train)\n",
        "\n",
        "        if task_type == 'binary':\n",
        "            self.generate_binary_classification_factors(X_train, y_processed, n_factors)\n",
        "        elif task_type == 'multiclass':\n",
        "            multiclass_factors = max(1, n_factors // 2)\n",
        "            ordinal_factors = n_factors - multiclass_factors\n",
        "            self.generate_multiclass_factors(X_train, y_processed, multiclass_factors)\n",
        "            self.generate_ordinal_factors(X_train, y_processed, ordinal_factors)\n",
        "        else:\n",
        "            self.generate_ordinal_factors(X_train, y_processed, n_factors)\n",
        "\n",
        "        print(f\"\\nTraining completed! Successfully trained {len(self.trained_models)} factors\")\n",
        "        return task_type\n",
        "\n",
        "    def apply_factors_to_full_data(self, full_df, feature_cols, target_col, task_type):\n",
        "        print(\"Step 2: Applying factors to full dataset\")\n",
        "\n",
        "        X_full, y_full = self.prepare_data(full_df, feature_cols, target_col)\n",
        "        y_processed, _ = self.prepare_classification_target(y_full)\n",
        "\n",
        "        for factor_name, model in self.trained_models.items():\n",
        "            try:\n",
        "                factor_values = self.apply_factor_to_data(X_full, model, factor_name, task_type)\n",
        "                self.generated_factors[factor_name] = factor_values\n",
        "\n",
        "                if task_type == 'binary' and 'binary' in factor_name:\n",
        "                    try:\n",
        "                        auc = roc_auc_score(y_processed, factor_values)\n",
        "                        print(f\"  {factor_name} full set AUC: {auc:.4f}\")\n",
        "                    except:\n",
        "                        corr = np.corrcoef(factor_values, y_processed)[0, 1]\n",
        "                        print(f\"  {factor_name} full set correlation: {corr:.4f}\")\n",
        "                else:\n",
        "                    corr = np.corrcoef(factor_values, y_processed)[0, 1]\n",
        "                    print(f\"  {factor_name} full set correlation: {corr:.4f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Failed to apply factor {factor_name} to full set: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"\\nFactor application completed! Successfully generated {len(self.generated_factors)} factors on full dataset\")\n",
        "\n",
        "    def generate_classification_factors(self, df, feature_cols, target_col, n_factors=10):\n",
        "\n",
        "        train_df, full_df = self.split_data(df)\n",
        "\n",
        "        task_type = self.train_factors(train_df, feature_cols, target_col, n_factors)\n",
        "\n",
        "        self.apply_factors_to_full_data(full_df, feature_cols, target_col, task_type)\n",
        "\n",
        "        return self.generated_factors\n",
        "\n",
        "    def get_factor_dataframe(self, original_df, id_col=None, time_col=None):\n",
        "\n",
        "        if not self.generated_factors:\n",
        "            return None\n",
        "\n",
        "        factor_df = pd.DataFrame(self.generated_factors, index=original_df.index)\n",
        "\n",
        "        if id_col:\n",
        "            for col in id_col if isinstance(id_col, list) else [id_col]:\n",
        "                if col in original_df.columns:\n",
        "                    factor_df[col] = original_df[col]\n",
        "\n",
        "        if time_col:\n",
        "            for col in time_col if isinstance(time_col, list) else [time_col]:\n",
        "                if col in original_df.columns:\n",
        "                    factor_df[col] = original_df[col]\n",
        "\n",
        "        return factor_df\n",
        "\n",
        "    def print_factor_expressions(self):\n",
        "        if not self.factor_expressions:\n",
        "            print(\"No factor expressions generated\")\n",
        "            return\n",
        "\n",
        "        print(\"Factor expressions:\")\n",
        "\n",
        "        for factor_name, expression in self.factor_expressions.items():\n",
        "            print(f\"{factor_name}: {expression}\")\n",
        "\n",
        "    def evaluate_factors_on_splits(self, df, feature_cols, target_col):\n",
        "        if not self.generated_factors:\n",
        "            print(\"No factors generated for evaluation\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"Factor performance evaluation (training set vs full set)\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        train_df, full_df = self.split_data(df)\n",
        "\n",
        "        X_train, y_train = self.prepare_data(train_df, feature_cols, target_col)\n",
        "        y_train_processed, task_type = self.prepare_classification_target(y_train)\n",
        "\n",
        "        X_full, y_full = self.prepare_data(full_df, feature_cols, target_col)\n",
        "        y_full_processed, _ = self.prepare_classification_target(y_full)\n",
        "\n",
        "        for factor_name, model in self.trained_models.items():\n",
        "            try:\n",
        "                train_factor_values = self.apply_factor_to_data(X_train, model, factor_name, task_type)\n",
        "\n",
        "                full_factor_values = self.generated_factors[factor_name]\n",
        "\n",
        "                if task_type == 'binary' and 'binary' in factor_name:\n",
        "                    try:\n",
        "                        train_auc = roc_auc_score(y_train_processed, train_factor_values)\n",
        "                        full_auc = roc_auc_score(y_full_processed, full_factor_values)\n",
        "                        print(f\"{factor_name}:\")\n",
        "                        print(f\"  Training set AUC: {train_auc:.4f}\")\n",
        "                        print(f\"  Full set AUC: {full_auc:.4f}\")\n",
        "                        print(f\"  Performance difference: {abs(full_auc - train_auc):.4f}\")\n",
        "                    except:\n",
        "                        train_corr = np.corrcoef(train_factor_values, y_train_processed)[0, 1]\n",
        "                        full_corr = np.corrcoef(full_factor_values, y_full_processed)[0, 1]\n",
        "                        print(f\"{factor_name}:\")\n",
        "                        print(f\"  Training set correlation: {train_corr:.4f}\")\n",
        "                        print(f\"  Full set correlation: {full_corr:.4f}\")\n",
        "                        print(f\"  Performance difference: {abs(full_corr - train_corr):.4f}\")\n",
        "                else:\n",
        "                    train_corr = np.corrcoef(train_factor_values, y_train_processed)[0, 1]\n",
        "                    full_corr = np.corrcoef(full_factor_values, y_full_processed)[0, 1]\n",
        "                    print(f\"{factor_name}:\")\n",
        "                    print(f\"  Training set correlation: {train_corr:.4f}\")\n",
        "                    print(f\"  Full set correlation: {full_corr:.4f}\")\n",
        "                    print(f\"  Performance difference: {abs(full_corr - train_corr):.4f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"{factor_name}: Evaluation failed - {e}\")\n",
        "\n",
        "def run_classification_genetic_generation(df, feature_cols, target_col, n_factors=10, train_ratio=0.7):\n",
        "    generator = ClassificationGeneticFactorGenerator(\n",
        "        population_size=300,\n",
        "        generations=8,\n",
        "        tournament_size=15,\n",
        "        random_state=42,\n",
        "        train_ratio=train_ratio\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        print(f\"Starting to generate {n_factors} classification factors...\")\n",
        "        print(f\"Using first {train_ratio*100:.0f}% of data for training, then applying to full dataset\")\n",
        "\n",
        "        generated_factors = generator.generate_classification_factors(\n",
        "            df, feature_cols, target_col, n_factors=n_factors\n",
        "        )\n",
        "\n",
        "        if not generated_factors:\n",
        "            print(\"Factor generation failed\")\n",
        "            return None, None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Generation process failed: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    factor_df = generator.get_factor_dataframe(df)\n",
        "\n",
        "    generator.print_factor_expressions()\n",
        "\n",
        "    generator.evaluate_factors_on_splits(df, feature_cols, target_col)\n",
        "\n",
        "    return generator, factor_df"
      ],
      "metadata": {
        "id": "HvRfn6luXz9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator, new_factors = run_classification_genetic_generation(\n",
        "    stock_data[all_features + [\"pred_ret\",\"year\"]],\n",
        "    all_features,\n",
        "    target_col='pred_ret',\n",
        "    n_factors=10\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqdJtaQP89KL",
        "outputId": "5c5e61ff-3a36-4549-bd12-b6f0d5c90cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to generate 10 classification factors...\n",
            "Using first 70% of data for training, then applying to full dataset\n",
            "============================================================\n",
            "Step 1: Training factors on training set\n",
            "============================================================\n",
            "Generating 10 ordinal factors...\n",
            "  genetic_ordinal_1 training correlation: -0.0001\n",
            "  genetic_ordinal_2 training correlation: -0.0001\n",
            "  genetic_ordinal_3 training correlation: -0.0021\n",
            "  genetic_ordinal_4 training correlation: -0.0001\n",
            "  genetic_ordinal_5 training correlation: -0.0001\n",
            "  genetic_ordinal_6 training correlation: -0.0001\n",
            "  genetic_ordinal_7 training correlation: -0.0001\n",
            "  genetic_ordinal_8 training correlation: nan\n",
            "  genetic_ordinal_9 training correlation: -0.0001\n",
            "  genetic_ordinal_10 training correlation: -0.0001\n",
            "\n",
            "Training completed! Successfully trained 10 factors\n",
            "Step 2: Applying factors to full dataset\n",
            "  genetic_ordinal_1 full set correlation: -0.0000\n",
            "  genetic_ordinal_2 full set correlation: -0.0000\n",
            "  genetic_ordinal_3 full set correlation: -0.0007\n",
            "  genetic_ordinal_4 full set correlation: -0.0000\n",
            "  genetic_ordinal_5 full set correlation: -0.0000\n",
            "  genetic_ordinal_6 full set correlation: -0.0000\n",
            "  genetic_ordinal_7 full set correlation: -0.0000\n",
            "  genetic_ordinal_8 full set correlation: nan\n",
            "  genetic_ordinal_9 full set correlation: -0.0000\n",
            "  genetic_ordinal_10 full set correlation: -0.0000\n",
            "\n",
            "Factor application completed! Successfully generated 10 factors on full dataset\n",
            "Factor expressions:\n",
            "genetic_ordinal_1: X6\n",
            "genetic_ordinal_2: X6\n",
            "genetic_ordinal_3: tanh(tanh(X24))\n",
            "genetic_ordinal_4: X6\n",
            "genetic_ordinal_5: X6\n",
            "genetic_ordinal_6: X6\n",
            "genetic_ordinal_7: X6\n",
            "genetic_ordinal_8: 0.021\n",
            "genetic_ordinal_9: X6\n",
            "genetic_ordinal_10: X6\n",
            "\n",
            "============================================================\n",
            "Factor performance evaluation (training set vs full set)\n",
            "============================================================\n",
            "genetic_ordinal_1:\n",
            "  Training set correlation: -0.0001\n",
            "  Full set correlation: -0.0000\n",
            "  Performance difference: 0.0000\n",
            "genetic_ordinal_2:\n",
            "  Training set correlation: -0.0001\n",
            "  Full set correlation: -0.0000\n",
            "  Performance difference: 0.0000\n",
            "genetic_ordinal_3:\n",
            "  Training set correlation: -0.0021\n",
            "  Full set correlation: -0.0007\n",
            "  Performance difference: 0.0014\n",
            "genetic_ordinal_4:\n",
            "  Training set correlation: -0.0001\n",
            "  Full set correlation: -0.0000\n",
            "  Performance difference: 0.0000\n",
            "genetic_ordinal_5:\n",
            "  Training set correlation: -0.0001\n",
            "  Full set correlation: -0.0000\n",
            "  Performance difference: 0.0000\n",
            "genetic_ordinal_6:\n",
            "  Training set correlation: -0.0001\n",
            "  Full set correlation: -0.0000\n",
            "  Performance difference: 0.0000\n",
            "genetic_ordinal_7:\n",
            "  Training set correlation: -0.0001\n",
            "  Full set correlation: -0.0000\n",
            "  Performance difference: 0.0000\n",
            "genetic_ordinal_8:\n",
            "  Training set correlation: nan\n",
            "  Full set correlation: nan\n",
            "  Performance difference: nan\n",
            "genetic_ordinal_9:\n",
            "  Training set correlation: -0.0001\n",
            "  Full set correlation: -0.0000\n",
            "  Performance difference: 0.0000\n",
            "genetic_ordinal_10:\n",
            "  Training set correlation: -0.0001\n",
            "  Full set correlation: -0.0000\n",
            "  Performance difference: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "constant_cols = [col for col in new_factors.columns if new_factors[col].nunique() <= 1]\n",
        "new_factors.drop(columns=constant_cols, inplace=True)"
      ],
      "metadata": {
        "id": "F94-ztMxPoyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uni_col = []\n",
        "for i in new_factors.columns:\n",
        "  if uni_col == []:\n",
        "    uni_col.append(i)\n",
        "  for j in uni_col:\n",
        "    if np.all(new_factors[i].values == new_factors[j].values):\n",
        "      break\n",
        "    uni_col.append(i)\n",
        "gp_factor = new_factors[uni_col].copy()"
      ],
      "metadata": {
        "id": "cwxHGtAyCEYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FastRandomForestFactorGenerator:\n",
        "    def __init__(self, n_estimators=200, random_state=42, n_jobs=-1, train_ratio=0.7):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.random_state = random_state\n",
        "        self.n_jobs = n_jobs\n",
        "        self.train_ratio = train_ratio\n",
        "\n",
        "        self.generated_factors = {}\n",
        "        self.factor_info = {}\n",
        "        self.rf_models = {}\n",
        "        self.label_encoder = None\n",
        "\n",
        "        self._X_train_processed = None\n",
        "        self._y_train_processed = None\n",
        "        self._task_type = None\n",
        "\n",
        "    def split_data(self, df, year=\"year\"):\n",
        "        n_train = int(len(df) * self.train_ratio)\n",
        "        train_df = df[df[\"year\"]<=2019].copy()\n",
        "        full_df = df.copy()\n",
        "\n",
        "        print(f\"Training set size: {len(train_df)} rows ({self.train_ratio*100:.0f}%)\")\n",
        "        print(f\"Full dataset size: {len(full_df)} rows (100%)\")\n",
        "\n",
        "        return train_df, full_df\n",
        "\n",
        "    def prepare_data(self, df, feature_cols, target_col=None, is_training=True):\n",
        "        print(\"Processing data...\")\n",
        "        X = df[feature_cols].copy()\n",
        "\n",
        "        numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
        "        X[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].median())\n",
        "        X[numeric_cols] = X[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
        "        X[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].median())\n",
        "\n",
        "        if target_col is not None:\n",
        "            y = df[target_col].copy()\n",
        "\n",
        "            if is_training:\n",
        "                if y.dtype == 'object' or len(np.unique(y)) <= 10:\n",
        "                    if y.dtype == 'object':\n",
        "                        self.label_encoder = LabelEncoder()\n",
        "                        y = self.label_encoder.fit_transform(y)\n",
        "                    else:\n",
        "                        self.label_encoder = LabelEncoder()\n",
        "                        y = self.label_encoder.fit_transform(y)\n",
        "                    self._task_type = 'classification'\n",
        "                else:\n",
        "                    y = y.fillna(y.median())\n",
        "                    y = y.replace([np.inf, -np.inf], np.nan).fillna(y.median())\n",
        "                    self._task_type = 'regression'\n",
        "\n",
        "                self._X_train_processed = X\n",
        "                self._y_train_processed = y\n",
        "            else:\n",
        "                if self._task_type == 'classification' and self.label_encoder is not None:\n",
        "                    try:\n",
        "                        y = self.label_encoder.transform(y)\n",
        "                    except ValueError:\n",
        "                        known_classes = set(self.label_encoder.classes_)\n",
        "                        y = y.apply(lambda x: x if x in known_classes else self.label_encoder.classes_[0])\n",
        "                        y = self.label_encoder.transform(y)\n",
        "                else:\n",
        "                    y = y.fillna(y.median())\n",
        "                    y = y.replace([np.inf, -np.inf], np.nan).fillna(y.median())\n",
        "\n",
        "            return X, y\n",
        "\n",
        "        return X\n",
        "\n",
        "    def _train_main_model(self, X_train, y_train):\n",
        "        print(f\"Training main model for {self._task_type}...\")\n",
        "\n",
        "        if self._task_type == 'classification':\n",
        "            rf = RandomForestClassifier(\n",
        "                n_estimators=self.n_estimators,\n",
        "                random_state=self.random_state,\n",
        "                n_jobs=self.n_jobs,\n",
        "                max_depth=8,\n",
        "                min_samples_split=50\n",
        "            )\n",
        "        else:\n",
        "            rf = RandomForestRegressor(\n",
        "                n_estimators=self.n_estimators,\n",
        "                random_state=self.random_state,\n",
        "                n_jobs=self.n_jobs,\n",
        "                max_depth=8,\n",
        "                min_samples_split=50\n",
        "            )\n",
        "\n",
        "        rf.fit(X_train, y_train)\n",
        "        self.rf_models['main'] = rf\n",
        "        self.rf_models['task_type'] = self._task_type\n",
        "\n",
        "        print(f\"Main model trained ({self._task_type})\")\n",
        "        return rf\n",
        "\n",
        "    def generate_tree_prediction_factors(self, X_train, y_train, n_factors=10):\n",
        "        print(f\"Generating {n_factors} tree prediction factors...\")\n",
        "\n",
        "        rf = self.rf_models.get('main')\n",
        "        if rf is None:\n",
        "            rf = self._train_main_model(X_train, y_train)\n",
        "\n",
        "        n_factors = min(n_factors, len(rf.estimators_))\n",
        "\n",
        "        for i in range(n_factors):\n",
        "            factor_name = f'rf_tree_pred_{i+1}'\n",
        "            self.factor_info[factor_name] = {\n",
        "                'type': 'tree_prediction',\n",
        "                'tree_index': i,\n",
        "                'task_type': self._task_type\n",
        "            }\n",
        "\n",
        "        print(f\"Configured {n_factors} tree prediction factors\")\n",
        "\n",
        "    def generate_leaf_index_factors(self, X_train, y_train, n_factors=8):\n",
        "        print(f\"Generating {n_factors} leaf index factors...\")\n",
        "\n",
        "        rf = self.rf_models.get('main')\n",
        "        if rf is None:\n",
        "            rf = self._train_main_model(X_train, y_train)\n",
        "\n",
        "        leaf_indices = rf.apply(X_train)\n",
        "        n_factors = min(n_factors, leaf_indices.shape[1])\n",
        "\n",
        "        for i in range(n_factors):\n",
        "            factor_name = f'rf_leaf_idx_{i+1}'\n",
        "            self.factor_info[factor_name] = {\n",
        "                'type': 'leaf_index',\n",
        "                'tree_index': i\n",
        "            }\n",
        "\n",
        "        print(f\"Configured {n_factors} leaf index factors\")\n",
        "\n",
        "    def generate_feature_importance_factors(self, X_train, y_train):\n",
        "        print(\"Generating feature importance factors...\")\n",
        "\n",
        "        rf = self.rf_models.get('main')\n",
        "        if rf is None:\n",
        "            rf = self._train_main_model(X_train, y_train)\n",
        "\n",
        "        main_importance = rf.feature_importances_\n",
        "        self.rf_models['main_importance'] = main_importance\n",
        "\n",
        "        importance_configs = ['main', 'squared', 'log']\n",
        "        for config in importance_configs:\n",
        "            factor_name = f'rf_importance_{config}'\n",
        "            self.factor_info[factor_name] = {\n",
        "                'type': 'feature_importance',\n",
        "                'config': config,\n",
        "                'top_features': list(X_train.columns[np.argsort(main_importance)[-5:][::-1]])\n",
        "            }\n",
        "\n",
        "        print(\"Configured 3 feature importance factors\")\n",
        "\n",
        "    def generate_bootstrap_factors(self, X_train, y_train, n_factors=6):\n",
        "        print(f\"Generating {n_factors} bootstrap factors...\")\n",
        "\n",
        "        rf = self.rf_models.get('main')\n",
        "        if rf is None:\n",
        "            rf = self._train_main_model(X_train, y_train)\n",
        "\n",
        "        for i in range(n_factors):\n",
        "            factor_name = f'rf_bootstrap_{i+1}'\n",
        "            self.factor_info[factor_name] = {\n",
        "                'type': 'bootstrap',\n",
        "                'bootstrap_seed': self.random_state + i,\n",
        "                'sample_ratio': 0.7\n",
        "            }\n",
        "\n",
        "        print(f\"Configured {n_factors} bootstrap factors\")\n",
        "\n",
        "    def generate_tree_depth_factors(self, X_train, y_train, n_factors=4):\n",
        "        print(f\"Generating {n_factors} tree depth factors...\")\n",
        "\n",
        "        rf = self.rf_models.get('main')\n",
        "        if rf is None:\n",
        "            rf = self._train_main_model(X_train, y_train)\n",
        "\n",
        "        leaf_indices = rf.apply(X_train)\n",
        "        n_factors = min(n_factors, leaf_indices.shape[1])\n",
        "\n",
        "        for i in range(n_factors):\n",
        "            factor_name = f'rf_depth_{i+1}'\n",
        "            self.factor_info[factor_name] = {\n",
        "                'type': 'tree_depth',\n",
        "                'tree_index': i\n",
        "            }\n",
        "\n",
        "        print(f\"Configured {n_factors} tree depth factors\")\n",
        "\n",
        "    def train_factors(self, train_df, feature_cols, target_col):\n",
        "        print(\"=\" * 60)\n",
        "        print(\"Step 1: Training random forest factors on training set\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        X_train, y_train = self.prepare_data(train_df, feature_cols, target_col, is_training=True)\n",
        "\n",
        "        self._train_main_model(X_train, y_train)\n",
        "\n",
        "        self.generate_tree_prediction_factors(X_train, y_train, n_factors=10)\n",
        "        self.generate_leaf_index_factors(X_train, y_train, n_factors=8)\n",
        "        self.generate_feature_importance_factors(X_train, y_train)\n",
        "        self.generate_bootstrap_factors(X_train, y_train, n_factors=6)\n",
        "        self.generate_tree_depth_factors(X_train, y_train, n_factors=4)\n",
        "\n",
        "        print(f\"\\nTraining completed! Successfully configured {len(self.factor_info)} factors\")\n",
        "        return self._task_type\n",
        "\n",
        "    def apply_factors_to_full_data(self, full_df, feature_cols, target_col, task_type):\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"Step 2: Applying factors to full dataset\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        X_full, y_full = self.prepare_data(full_df, feature_cols, target_col, is_training=False)\n",
        "        rf = self.rf_models['main']\n",
        "\n",
        "        for factor_name, info in self.factor_info.items():\n",
        "            try:\n",
        "                factor_type = info['type']\n",
        "\n",
        "                if factor_type == 'tree_prediction':\n",
        "                    tree_idx = info['tree_index']\n",
        "                    if task_type == 'classification':\n",
        "                        tree_probs = rf.estimators_[tree_idx].predict_proba(X_full)\n",
        "                        if tree_probs.shape[1] > 1:\n",
        "                            factor_values = tree_probs[:, 1]\n",
        "                        else:\n",
        "                            factor_values = tree_probs[:, 0]\n",
        "                    else:\n",
        "                        factor_values = rf.estimators_[tree_idx].predict(X_full)\n",
        "\n",
        "                elif factor_type == 'leaf_index':\n",
        "                    tree_idx = info['tree_index']\n",
        "                    leaf_indices = rf.apply(X_full)\n",
        "                    factor_values = leaf_indices[:, tree_idx].astype(float)\n",
        "\n",
        "                elif factor_type == 'feature_importance':\n",
        "                    config = info['config']\n",
        "                    main_importance = self.rf_models['main_importance']\n",
        "\n",
        "                    if config == 'main':\n",
        "                        weighted_importance = main_importance\n",
        "                    elif config == 'squared':\n",
        "                        weighted_importance = main_importance ** 2\n",
        "                        weighted_importance = weighted_importance / weighted_importance.sum()\n",
        "                    elif config == 'log':\n",
        "                        weighted_importance = np.log(main_importance + 1e-8)\n",
        "                        weighted_importance = (weighted_importance - weighted_importance.min()) / (weighted_importance.max() - weighted_importance.min() + 1e-8)\n",
        "\n",
        "                    factor_values = np.dot(X_full, weighted_importance)\n",
        "\n",
        "                elif factor_type == 'bootstrap':\n",
        "                    bootstrap_seed = info['bootstrap_seed']\n",
        "                    sample_ratio = info['sample_ratio']\n",
        "\n",
        "                    np.random.seed(bootstrap_seed)\n",
        "                    sample_size = int(sample_ratio * len(X_full))\n",
        "                    sample_idx = np.random.choice(len(X_full), size=sample_size, replace=True)\n",
        "\n",
        "                    if task_type == 'classification':\n",
        "                        base_predictions = rf.predict_proba(X_full)\n",
        "                        if base_predictions.shape[1] > 1:\n",
        "                            base_predictions = base_predictions[:, 1]\n",
        "                        else:\n",
        "                            base_predictions = base_predictions[:, 0]\n",
        "                    else:\n",
        "                        base_predictions = rf.predict(X_full)\n",
        "\n",
        "                    base_predictions = base_predictions.astype(np.float64)\n",
        "\n",
        "                    X_sample = X_full.iloc[sample_idx] if hasattr(X_full, 'iloc') else X_full[sample_idx]\n",
        "                    if task_type == 'classification':\n",
        "                        sample_predictions = rf.predict_proba(X_sample)\n",
        "                        if sample_predictions.shape[1] > 1:\n",
        "                            sample_predictions = sample_predictions[:, 1]\n",
        "                        else:\n",
        "                            sample_predictions = sample_predictions[:, 0]\n",
        "                    else:\n",
        "                        sample_predictions = rf.predict(X_sample)\n",
        "\n",
        "                    sample_predictions = sample_predictions.astype(np.float64)\n",
        "\n",
        "                    factor_values = base_predictions.copy()\n",
        "                    factor_values[sample_idx] = sample_predictions\n",
        "\n",
        "                    unsampled_mask = np.ones(len(X_full), dtype=bool)\n",
        "                    unsampled_mask[sample_idx] = False\n",
        "                    bootstrap_idx = int(factor_name.split('_')[-1]) - 1\n",
        "                    factor_values[unsampled_mask] *= (0.95 + bootstrap_idx * 0.01)\n",
        "\n",
        "                elif factor_type == 'tree_depth':\n",
        "                    tree_idx = info['tree_index']\n",
        "                    leaf_indices = rf.apply(X_full)\n",
        "                    depths = leaf_indices[:, tree_idx].astype(float)\n",
        "                    factor_values = (depths - depths.min()) / (depths.max() - depths.min() + 1e-8)\n",
        "\n",
        "                factor_values = factor_values.astype(np.float64)\n",
        "                self.generated_factors[factor_name] = factor_values\n",
        "\n",
        "                try:\n",
        "                    if task_type == 'classification' and 'tree_pred' in factor_name:\n",
        "                        auc = roc_auc_score(y_full, factor_values)\n",
        "                        print(f\"  {factor_name} full set AUC: {auc:.4f}\")\n",
        "                    else:\n",
        "                        corr = np.corrcoef(factor_values, y_full)[0, 1]\n",
        "                        if not np.isnan(corr):\n",
        "                            print(f\"  {factor_name} full set correlation: {corr:.4f}\")\n",
        "                except:\n",
        "                    print(f\"  {factor_name} generated\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Factor {factor_name} application failed: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"\\nFactor application completed! Successfully generated {len(self.generated_factors)} factors on full dataset\")\n",
        "\n",
        "    def generate_all_rf_factors(self, df, feature_cols, target_col):\n",
        "        print(\"=\" * 60)\n",
        "        print(\"Starting FAST Random Forest Factor Generation\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        train_df, full_df = self.split_data(df)\n",
        "\n",
        "        task_type = self.train_factors(train_df, feature_cols, target_col)\n",
        "\n",
        "        self.apply_factors_to_full_data(full_df, feature_cols, target_col, task_type)\n",
        "\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Generated {len(self.generated_factors)} factors successfully!\")\n",
        "        print(f\"Models trained: 1 (vs ~3-5 in slow version)\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        return self.generated_factors\n",
        "\n",
        "    def get_factor_dataframe(self, original_df):\n",
        "        if not self.generated_factors:\n",
        "            print(\"No factors were generated\")\n",
        "            return None\n",
        "\n",
        "        factor_df = pd.DataFrame(self.generated_factors, index=original_df.index)\n",
        "        return factor_df\n",
        "\n",
        "    def get_factor_summary(self):\n",
        "        if not self.generated_factors:\n",
        "            return None\n",
        "\n",
        "        summary_data = []\n",
        "        for factor_name, factor_values in self.generated_factors.items():\n",
        "            info = self.factor_info.get(factor_name, {})\n",
        "            summary_data.append({\n",
        "                'factor_name': factor_name,\n",
        "                'type': info.get('type', 'unknown'),\n",
        "                'mean': np.mean(factor_values),\n",
        "                'std': np.std(factor_values),\n",
        "                'min': np.min(factor_values),\n",
        "                'max': np.max(factor_values),\n",
        "                'unique_values': len(np.unique(factor_values)),\n",
        "                'info': str(info)\n",
        "            })\n",
        "\n",
        "        summary_df = pd.DataFrame(summary_data)\n",
        "        return summary_df\n",
        "\n",
        "    def evaluate_factors_on_splits(self, df, feature_cols, target_col):\n",
        "        if not self.generated_factors:\n",
        "            print(\"No factors generated for evaluation\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"Factor performance evaluation (training set vs full set)\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        train_df, full_df = self.split_data(df)\n",
        "\n",
        "        X_train, y_train = self.prepare_data(train_df, feature_cols, target_col, is_training=True)\n",
        "\n",
        "        X_full, y_full = self.prepare_data(full_df, feature_cols, target_col, is_training=False)\n",
        "\n",
        "        rf = self.rf_models['main']\n",
        "        task_type = self._task_type\n",
        "\n",
        "        for factor_name in self.generated_factors.keys():\n",
        "            try:\n",
        "                info = self.factor_info[factor_name]\n",
        "                factor_type = info['type']\n",
        "\n",
        "                if factor_type == 'tree_prediction':\n",
        "                    tree_idx = info['tree_index']\n",
        "                    if task_type == 'classification':\n",
        "                        tree_probs = rf.estimators_[tree_idx].predict_proba(X_train)\n",
        "                        if tree_probs.shape[1] > 1:\n",
        "                            train_factor_values = tree_probs[:, 1]\n",
        "                        else:\n",
        "                            train_factor_values = tree_probs[:, 0]\n",
        "                    else:\n",
        "                        train_factor_values = rf.estimators_[tree_idx].predict(X_train)\n",
        "\n",
        "                elif factor_type == 'leaf_index':\n",
        "                    tree_idx = info['tree_index']\n",
        "                    leaf_indices = rf.apply(X_train)\n",
        "                    train_factor_values = leaf_indices[:, tree_idx].astype(float)\n",
        "\n",
        "                else:\n",
        "                    train_factor_values = None\n",
        "\n",
        "                full_factor_values = self.generated_factors[factor_name]\n",
        "\n",
        "                if train_factor_values is not None:\n",
        "                    if task_type == 'classification' and 'tree_pred' in factor_name:\n",
        "                        try:\n",
        "                            train_auc = roc_auc_score(y_train, train_factor_values)\n",
        "                            full_auc = roc_auc_score(y_full, full_factor_values)\n",
        "                            print(f\"{factor_name}:\")\n",
        "                            print(f\"  Training set AUC: {train_auc:.4f}\")\n",
        "                            print(f\"  Full set AUC: {full_auc:.4f}\")\n",
        "                            print(f\"  Performance difference: {abs(full_auc - train_auc):.4f}\")\n",
        "                        except:\n",
        "                            train_corr = np.corrcoef(train_factor_values, y_train)[0, 1]\n",
        "                            full_corr = np.corrcoef(full_factor_values, y_full)[0, 1]\n",
        "                            if not (np.isnan(train_corr) or np.isnan(full_corr)):\n",
        "                                print(f\"{factor_name}:\")\n",
        "                                print(f\"  Training set correlation: {train_corr:.4f}\")\n",
        "                                print(f\"  Full set correlation: {full_corr:.4f}\")\n",
        "                                print(f\"  Performance difference: {abs(full_corr - train_corr):.4f}\")\n",
        "                    else:\n",
        "                        train_corr = np.corrcoef(train_factor_values, y_train)[0, 1]\n",
        "                        full_corr = np.corrcoef(full_factor_values, y_full)[0, 1]\n",
        "                        if not (np.isnan(train_corr) or np.isnan(full_corr)):\n",
        "                            print(f\"{factor_name}:\")\n",
        "                            print(f\"  Training set correlation: {train_corr:.4f}\")\n",
        "                            print(f\"  Full set correlation: {full_corr:.4f}\")\n",
        "                            print(f\"  Performance difference: {abs(full_corr - train_corr):.4f}\")\n",
        "                else:\n",
        "                    full_corr = np.corrcoef(full_factor_values, y_full)[0, 1]\n",
        "                    if not np.isnan(full_corr):\n",
        "                        print(f\"{factor_name}: Full set correlation: {full_corr:.4f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"{factor_name}: Evaluation failed - {e}\")\n",
        "\n",
        "    def evaluate_factors(self, df, target_col):\n",
        "        if not self.generated_factors:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            target = df[target_col].fillna(df[target_col].median())\n",
        "            if self.label_encoder is not None and target.dtype == 'object':\n",
        "                target = self.label_encoder.transform(target)\n",
        "        except:\n",
        "            target = df[target_col].fillna(df[target_col].median())\n",
        "\n",
        "        evaluation_results = []\n",
        "\n",
        "        for factor_name, factor_values in self.generated_factors.items():\n",
        "            try:\n",
        "                corr = np.corrcoef(factor_values, target)[0, 1]\n",
        "                if np.isnan(corr):\n",
        "                    corr = 0\n",
        "            except:\n",
        "                corr = 0\n",
        "\n",
        "            factor_std = np.std(factor_values)\n",
        "            unique_ratio = len(np.unique(factor_values)) / len(factor_values)\n",
        "\n",
        "            evaluation_results.append({\n",
        "                'factor_name': factor_name,\n",
        "                'type': self.factor_info.get(factor_name, {}).get('type', 'unknown'),\n",
        "                'correlation': corr,\n",
        "                'abs_correlation': abs(corr),\n",
        "                'std': factor_std,\n",
        "                'unique_ratio': unique_ratio\n",
        "            })\n",
        "\n",
        "        eval_df = pd.DataFrame(evaluation_results)\n",
        "        eval_df = eval_df.sort_values('abs_correlation', ascending=False)\n",
        "\n",
        "        print(\"\\nTop 10 factors by correlation:\")\n",
        "        print(eval_df.head(10)[['factor_name', 'type', 'correlation', 'unique_ratio']])\n",
        "\n",
        "        return eval_df\n",
        "\n",
        "def run_fast_rf_factor_generation(df, target_col, feature_cols=None, n_jobs=-1, train_ratio=0.7):\n",
        "    if feature_cols is None:\n",
        "        feature_cols = [col for col in df.columns if col != target_col]\n",
        "\n",
        "    print(f\"Target column: {target_col}\")\n",
        "    print(f\"Found {len(feature_cols)} feature columns\")\n",
        "    print(f\"Data shape: {df.shape}\")\n",
        "    print(f\"Train ratio: {train_ratio*100:.0f}%\")\n",
        "\n",
        "    generator = FastRandomForestFactorGenerator(\n",
        "        n_estimators=200,\n",
        "        random_state=42,\n",
        "        n_jobs=n_jobs,\n",
        "        train_ratio=train_ratio\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        print(f\"Starting random forest factor generation...\")\n",
        "        print(f\"Using first {train_ratio*100:.0f}% of data for training, then applying to full dataset\")\n",
        "\n",
        "        generated_factors = generator.generate_all_rf_factors(df, feature_cols, target_col)\n",
        "\n",
        "        if not generated_factors:\n",
        "            print(\"Factor generation failed\")\n",
        "            return None, None, None, None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Generation process failed: {e}\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    factor_df = generator.get_factor_dataframe(df)\n",
        "\n",
        "    summary = generator.get_factor_summary()\n",
        "    if summary is not None:\n",
        "        print(\"\\nFactor types summary:\")\n",
        "        print(summary.groupby('type').size())\n",
        "\n",
        "    generator.evaluate_factors_on_splits(df, feature_cols, target_col)\n",
        "\n",
        "    evaluation_results = generator.evaluate_factors(df, target_col)\n",
        "\n",
        "    return generator, factor_df, summary, evaluation_results"
      ],
      "metadata": {
        "id": "j7o7G_DyQbEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator, factor_df, summary, evaluation = run_fast_rf_factor_generation(\n",
        "    stock_data[all_features+[\"pred_cat\", \"year\"] ],\n",
        "    target_col='pred_cat'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMnOZWFkRwvY",
        "outputId": "3a44d626-fd8d-4e38-d69d-9a99ed5e0e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target column: pred_cat\n",
            "Found 28 feature columns\n",
            "Data shape: (1286513, 29)\n",
            "Train ratio: 70%\n",
            "Starting random forest factor generation...\n",
            "Using first 70% of data for training, then applying to full dataset\n",
            "============================================================\n",
            "Starting FAST Random Forest Factor Generation\n",
            "============================================================\n",
            "Training set size: 823802 rows (70%)\n",
            "Full dataset size: 1286513 rows (100%)\n",
            "============================================================\n",
            "Step 1: Training random forest factors on training set\n",
            "============================================================\n",
            "Processing data...\n",
            "Training main model for classification...\n",
            "Main model trained (classification)\n",
            "Generating 10 tree prediction factors...\n",
            "Configured 10 tree prediction factors\n",
            "Generating 8 leaf index factors...\n",
            "Configured 8 leaf index factors\n",
            "Generating feature importance factors...\n",
            "Configured 3 feature importance factors\n",
            "Generating 6 bootstrap factors...\n",
            "Configured 6 bootstrap factors\n",
            "Generating 4 tree depth factors...\n",
            "Configured 4 tree depth factors\n",
            "\n",
            "Training completed! Successfully configured 31 factors\n",
            "\n",
            "============================================================\n",
            "Step 2: Applying factors to full dataset\n",
            "============================================================\n",
            "Processing data...\n",
            "  rf_tree_pred_1 full set AUC: 0.6361\n",
            "  rf_tree_pred_2 full set AUC: 0.6392\n",
            "  rf_tree_pred_3 full set AUC: 0.6124\n",
            "  rf_tree_pred_4 full set AUC: 0.6155\n",
            "  rf_tree_pred_5 full set AUC: 0.6059\n",
            "  rf_tree_pred_6 full set AUC: 0.6448\n",
            "  rf_tree_pred_7 full set AUC: 0.6284\n",
            "  rf_tree_pred_8 full set AUC: 0.6076\n",
            "  rf_tree_pred_9 full set AUC: 0.6144\n",
            "  rf_tree_pred_10 full set AUC: 0.5991\n",
            "  rf_leaf_idx_1 full set correlation: 0.0553\n",
            "  rf_leaf_idx_2 full set correlation: 0.0723\n",
            "  rf_leaf_idx_3 full set correlation: -0.0708\n",
            "  rf_leaf_idx_4 full set correlation: 0.0255\n",
            "  rf_leaf_idx_5 full set correlation: -0.0843\n",
            "  rf_leaf_idx_6 full set correlation: 0.0325\n",
            "  rf_leaf_idx_7 full set correlation: 0.0527\n",
            "  rf_leaf_idx_8 full set correlation: 0.0576\n",
            "  rf_importance_main full set correlation: -0.0089\n",
            "  rf_importance_squared full set correlation: 0.0127\n",
            "  rf_importance_log full set correlation: -0.0268\n",
            "  rf_bootstrap_1 full set correlation: 0.3253\n",
            "  rf_bootstrap_2 full set correlation: 0.3263\n",
            "  rf_bootstrap_3 full set correlation: 0.3270\n",
            "  rf_bootstrap_4 full set correlation: 0.3275\n",
            "  rf_bootstrap_5 full set correlation: 0.3279\n",
            "  rf_bootstrap_6 full set correlation: 0.3279\n",
            "  rf_depth_1 full set correlation: 0.0553\n",
            "  rf_depth_2 full set correlation: 0.0723\n",
            "  rf_depth_3 full set correlation: -0.0708\n",
            "  rf_depth_4 full set correlation: 0.0255\n",
            "\n",
            "Factor application completed! Successfully generated 31 factors on full dataset\n",
            "============================================================\n",
            "Generated 31 factors successfully!\n",
            "Models trained: 1 (vs ~3-5 in slow version)\n",
            "============================================================\n",
            "\n",
            "Factor types summary:\n",
            "type\n",
            "bootstrap              6\n",
            "feature_importance     3\n",
            "leaf_index             8\n",
            "tree_depth             4\n",
            "tree_prediction       10\n",
            "dtype: int64\n",
            "\n",
            "============================================================\n",
            "Factor performance evaluation (training set vs full set)\n",
            "============================================================\n",
            "Training set size: 823802 rows (70%)\n",
            "Full dataset size: 1286513 rows (100%)\n",
            "Processing data...\n",
            "Processing data...\n",
            "rf_tree_pred_1:\n",
            "  Training set AUC: 0.6810\n",
            "  Full set AUC: 0.6361\n",
            "  Performance difference: 0.0450\n",
            "rf_tree_pred_2:\n",
            "  Training set AUC: 0.6940\n",
            "  Full set AUC: 0.6392\n",
            "  Performance difference: 0.0548\n",
            "rf_tree_pred_3:\n",
            "  Training set AUC: 0.6863\n",
            "  Full set AUC: 0.6124\n",
            "  Performance difference: 0.0739\n",
            "rf_tree_pred_4:\n",
            "  Training set AUC: 0.6782\n",
            "  Full set AUC: 0.6155\n",
            "  Performance difference: 0.0628\n",
            "rf_tree_pred_5:\n",
            "  Training set AUC: 0.6768\n",
            "  Full set AUC: 0.6059\n",
            "  Performance difference: 0.0709\n",
            "rf_tree_pred_6:\n",
            "  Training set AUC: 0.6977\n",
            "  Full set AUC: 0.6448\n",
            "  Performance difference: 0.0530\n",
            "rf_tree_pred_7:\n",
            "  Training set AUC: 0.6888\n",
            "  Full set AUC: 0.6284\n",
            "  Performance difference: 0.0604\n",
            "rf_tree_pred_8:\n",
            "  Training set AUC: 0.6641\n",
            "  Full set AUC: 0.6076\n",
            "  Performance difference: 0.0565\n",
            "rf_tree_pred_9:\n",
            "  Training set AUC: 0.6759\n",
            "  Full set AUC: 0.6144\n",
            "  Performance difference: 0.0615\n",
            "rf_tree_pred_10:\n",
            "  Training set AUC: 0.6539\n",
            "  Full set AUC: 0.5991\n",
            "  Performance difference: 0.0548\n",
            "rf_leaf_idx_1:\n",
            "  Training set correlation: 0.0859\n",
            "  Full set correlation: 0.0553\n",
            "  Performance difference: 0.0305\n",
            "rf_leaf_idx_2:\n",
            "  Training set correlation: 0.0944\n",
            "  Full set correlation: 0.0723\n",
            "  Performance difference: 0.0221\n",
            "rf_leaf_idx_3:\n",
            "  Training set correlation: -0.0888\n",
            "  Full set correlation: -0.0708\n",
            "  Performance difference: 0.0180\n",
            "rf_leaf_idx_4:\n",
            "  Training set correlation: 0.0537\n",
            "  Full set correlation: 0.0255\n",
            "  Performance difference: 0.0283\n",
            "rf_leaf_idx_5:\n",
            "  Training set correlation: -0.0849\n",
            "  Full set correlation: -0.0843\n",
            "  Performance difference: 0.0006\n",
            "rf_leaf_idx_6:\n",
            "  Training set correlation: 0.0390\n",
            "  Full set correlation: 0.0325\n",
            "  Performance difference: 0.0065\n",
            "rf_leaf_idx_7:\n",
            "  Training set correlation: 0.0533\n",
            "  Full set correlation: 0.0527\n",
            "  Performance difference: 0.0006\n",
            "rf_leaf_idx_8:\n",
            "  Training set correlation: 0.0682\n",
            "  Full set correlation: 0.0576\n",
            "  Performance difference: 0.0105\n",
            "rf_importance_main: Full set correlation: -0.0089\n",
            "rf_importance_squared: Full set correlation: 0.0127\n",
            "rf_importance_log: Full set correlation: -0.0268\n",
            "rf_bootstrap_1: Full set correlation: 0.3253\n",
            "rf_bootstrap_2: Full set correlation: 0.3263\n",
            "rf_bootstrap_3: Full set correlation: 0.3270\n",
            "rf_bootstrap_4: Full set correlation: 0.3275\n",
            "rf_bootstrap_5: Full set correlation: 0.3279\n",
            "rf_bootstrap_6: Full set correlation: 0.3279\n",
            "rf_depth_1: Full set correlation: 0.0553\n",
            "rf_depth_2: Full set correlation: 0.0723\n",
            "rf_depth_3: Full set correlation: -0.0708\n",
            "rf_depth_4: Full set correlation: 0.0255\n",
            "\n",
            "Top 10 factors by correlation:\n",
            "       factor_name             type  correlation  unique_ratio\n",
            "26  rf_bootstrap_6        bootstrap     0.327927      0.990175\n",
            "25  rf_bootstrap_5        bootstrap     0.327869      0.993190\n",
            "24  rf_bootstrap_4        bootstrap     0.327484      0.993186\n",
            "23  rf_bootstrap_3        bootstrap     0.326971      0.993195\n",
            "22  rf_bootstrap_2        bootstrap     0.326335      0.993163\n",
            "21  rf_bootstrap_1        bootstrap     0.325320      0.993167\n",
            "5   rf_tree_pred_6  tree_prediction     0.252807      0.000175\n",
            "1   rf_tree_pred_2  tree_prediction     0.244387      0.000188\n",
            "0   rf_tree_pred_1  tree_prediction     0.235110      0.000175\n",
            "6   rf_tree_pred_7  tree_prediction     0.221399      0.000190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extra_factor = pd.concat([factor_df, gp_factor],axis =1)"
      ],
      "metadata": {
        "id": "KBbOkoLKXbcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extra_factor"
      ],
      "metadata": {
        "id": "96gGSOl-HvOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extra_factor.to_csv(\"/content/drive/MyDrive/extra_factor.csv\")"
      ],
      "metadata": {
        "id": "Sz8VSAMICykh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}